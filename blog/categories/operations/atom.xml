<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Operations | Miker]]></title>
  <link href="http://rowehl.com/blog/categories/operations/atom.xml" rel="self"/>
  <link href="http://rowehl.com/"/>
  <updated>2013-09-20T15:02:28-04:00</updated>
  <id>http://rowehl.com/</id>
  <author>
    <name><![CDATA[Mike Rowehl]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[knife-block for Chef Testing]]></title>
    <link href="http://rowehl.com/blog/2013/09/19/knife-block-for-chef-testing/"/>
    <updated>2013-09-19T12:17:00-04:00</updated>
    <id>http://rowehl.com/blog/2013/09/19/knife-block-for-chef-testing</id>
    <content type="html"><![CDATA[<p>A few weeks ago <a href="https://github.com/nathenharvey">Nathen Harvey</a> was kind
enough to stop by and give us a critique of how we do Chef automated testing
and some workflow suggestions. We had been using chef-solo
to do some of the recipe development and automated testing, but all our real
deployments were done using chef-client. And the differences
between solo runs and chef-client runs kept biting us. We had seen the stuff
Lookout Mobile has done to
<a href="http://hackers.lookout.com/2012/04/cookout-at-lookout-with-chef/">run a VM for the chef server</a>
in addition to the node during testing. But that seemed like an awful lot of
overhead. Fortunately Nathen gave us the awesome hack of using different
organizations for the different developers of chef rules, different
organizations for CI, and then the production organization. That gives us
complete isolation of the different working areas, but still keeps setup
relatively simple. w00T!</p>

<p>His suggestion was to use
<a href="https://github.com/greenandsecure/knife-block">the knife-block plugin</a>
to make swapping around between organizations easier. Definitely an awesome
tool, and very useful. But we ran into a few issues because
knife-block uses a different method for finding it's knife.rb file than the
knife command does. So I pushed up a
<a href="https://github.com/mikerowehl/knife-block">fork of the original knife-block code</a>
with a change to how it picks up the configuration location. This version uses
the Chef::Knife config loader to find the actual configuration being used,
and uses that directly. In the original version it borrowed a function from
Chef, but that function tried to find knife config by looking for a .chef
directory somewhere in the parent directories on the filesystem. The real
Chef config loader looking in a bunch of additional places.
So the result was that if you had your
config in ~/.chef and ran your knife block commands from your home dir it worked
fine, but if you cd into /tmp suddenly your knife block commands
would freak out.</p>

<p>Once I dug in and saw what was going on, I figured it would be pretty easy to
fix up. After looking at the Chef code it became obvious why the knife-block
stuff did things the way it did. I hate to have to monkey patch to get things
to work, but the change is actually pretty trivial. I ended up
<a href="https://github.com/mikerowehl/knife-block/blob/494b8c08a45c17c1335a97e4a6a6b08ecdc73c11/lib/chef/knife/block.rb">injecting a get_config_file method</a>
into Chef::Knife so that once I constructed a Knife object I could ask it for
the location of the chef config file. Now if knife itself works, I'm sure
knife-block will end up pulling config from the same location. Useful for when
I need to login to the CI server and poke around to do some debugging
(Bamboo stores the test files outside of the home directory of the bamboo
user in our configuration).</p>

<p>For the testing itself we use some Vagrantfiles with definitions of the
different server types we have. Knife-block provides a nice easy way for me
to test against an mrowehl organization, and then use a devops-test
organization for some automated validation, and finally swap to the prod
organization to push stuff up live. So of course I want to be able to use
the Vagrantfile when I'm testing locally and developing recipes, and use the
same Vagrantfile on the Bamboo server with the devops-test organization to
validate that everything is working. I didn't want to have to go in and edit
the chef-client provisioner config to swap organizations though, and using
something like environment variables to drive it just seemed really ugly.
Fortunately we ran across
<a href="https://coderwall.com/p/dt1idw">this post about pulling vagrant chef-client config from knife.rb</a>
and ended up putting together
<a href="https://gist.github.com/mikerowehl/6631396">our Vagrantfiles so they automatically follow where knife-block is pointed</a>.
Together with the changes in the Vagrant 1.3 series releases to automatically
remove node and client from the server when you do a 'vagrant destroy' it
makes for an awesome testing setup. Just use knife block to swap around to
different organizations and up/destroy your boxes as much as you want,
your wanton path of destruction just gets all swept up automatically behind
you.</p>

<p>With the vagrant config hackery in place it doesn't matter what
organization we want to test against, the text
of the Vagrantfile can stay the same as long as knife is pointed to the right
place. That made it pretty trivial to put together a simple
<a href="https://gist.github.com/mikerowehl/6631010">wrapper Rakefile to clear and populate the organizations</a>.
With those wrappers all our Bamboo server has to do is:</p>

<ul>
<li>grab the latest from our chef-repo with git</li>
<li>'knife block use devops' to swap to our test organization</li>
<li>'rake delete_all' to clean out the test organization</li>
<li>'rake upload_all' to put all the new cookbooks in place</li>
<li>'vagrant up' for the actual test</li>
<li>and then a run always ending task to 'vagrant destroy -f'</li>
</ul>


<p>Fortunately the vagrant up command returns the exit status of the chef-client
run as the status for the command, so picking up failures is pretty trivial.</p>

<p>Of course, this stuff isn't perfect. The tests always run in our 'dev'
environment, which has the cookbook versions unpinned. That's how we can clean
out and reload the organization each time without it causing trouble. Of
course if you had pinned cookbook versions you would have to add in some logic
to make sure you could load the proper version each time you reload. But for
our current level of complexity, just knowing that the latest batch of changes
doesn't completely break is an awesome start.</p>

<p>It's not quite ready for a release yet, but I've also got
<a href="http://www.packer.io/">some Packer templates</a> which converge a node using
chef-client and export the Vagrant friendly box so I can distribute the VM.
Once I have them cleaned up a bit I'll post those too.</p>

<p>Update: The change for knife-block to follow the same knife.rb lookup logic
as Chef has been
<a href="https://github.com/greenandsecure/knife-block/pull/10">merged into the main repo</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scaling Technology]]></title>
    <link href="http://rowehl.com/blog/2013/07/14/scaling-technology/"/>
    <updated>2013-07-14T17:41:00-04:00</updated>
    <id>http://rowehl.com/blog/2013/07/14/scaling-technology</id>
    <content type="html"><![CDATA[<p>A few weeks ago Arte and Mario asked me to swing by to chat with folks participating in
<a href="http://momentum.mobilemonday.us/">the Momentum accelerator</a> to talk about
scaling technology. While we were talking I pointed folks to a few posts and videos of
talks I consider to be some of the root nodes of a lot of other conversations. I'm not
sure I've ever pulled this together before.</p>

<ul>
<li><a href="http://blip.tv/oreilly-velocity-conference/velocity-09-john-allspaw-10-deploys-per-day-dev-and-ops-cooperation-at-flickr-2297883">Allspaw/Hammond - 10+ Deploys Per Day</a></li>
<li><a href="http://www.slideshare.net/deimos/randy-shoup-ebays-architectural-principles">Randy Shoup - Ebay's Architectural Principles</a></li>
<li><a href="http://akfpartners.com/techblog/2008/05/08/splitting-applications-or-services-for-scale/">AKF Partners - Splitting Applications or Services for Scale</a></li>
<li><a href="http://highscalability.com/">High Scalability</a></li>
<li><a href="http://techblog.netflix.com/">Netflix Tech Blog</a></li>
</ul>


<p>That Allspaw/Hammond presentation is the most primary in my opinion. It's the talk
that lots of us consider to be the inflection point of the devops movement, when the
practice started to really gain visibility. What had previously been a random
collection of techniques we didn't have a great way to refer to became "devops".
There's a ton of useful information in that presentation. Not just the overall
concepts of dev and ops working together with a different kind of coupling, but some
specific tools to make that happen like shared metrics, feature flags, and shipping
dark.</p>

<p>The presentation from Randy Shoup has also withstood the test of time fantastically
well. The four architectural principles are great top level items: partition
everything, async everywhere, automate everything, remember everything fails. And the
presentation from AKF Partners dives into a bunch more detail about how to partition
services so that you can just throw hardware at problems. That model also provides a
lot of the basis for most of the conversations I end up having about geographic
distribution of services (which actually sounds exactly like a discussion about how
to design the I/O layer of an operating system, you just swap terminology).</p>

<p>The High Scalability and Netflix blogs provide great concrete examples of what some
of the problems and solutions look like. Principles are great, but like always
there's more than one way to do it. So it's great to have some concrete examples to
poke through. Plus Netflix being one of the pioneers of the static AMI methodology
of infrastructure automation it makes their approaches particularly strongly
opinionated.</p>

<p>The platforms themselves have changed the level of abstraction you need to work at
when putting this stuff into practice. Thanks to MongoDB and Riak we don't have to
wrapper tons of instances of MySQL or Postgres to make a datastore that scales
horizontally. And thanks to services like Elastic Beanstalk, Heroku, and EngineYard
we don't have to pay as much attention to how to distribute load across multiple
application servers. But even though you can count on your platform to remove a
bunch of the details in some cases, it's a good idea to understand the principles.
First of all cause it's possible to misuse the platform and end up not
getting the full advantage you could. But also because platforms can only help out
so far. Eventually you need to crack open the abstractions and either continue
with an application optimized line of evolution, or figure out how to wrapper
additional layers of capability around what the base platform provide. In either
case at least being aware of the principles your underlying platforms are working
on will pay back hugely.</p>
]]></content>
  </entry>
  
</feed>
