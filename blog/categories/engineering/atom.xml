<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Engineering | Miker]]></title>
  <link href="http://rowehl.com/blog/categories/engineering/atom.xml" rel="self"/>
  <link href="http://rowehl.com/"/>
  <updated>2013-11-03T17:11:35-08:00</updated>
  <id>http://rowehl.com/</id>
  <author>
    <name><![CDATA[Mike Rowehl]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Firefox OS with App Manager]]></title>
    <link href="http://rowehl.com/blog/2013/10/28/firefox-os-with-app-manager/"/>
    <updated>2013-10-28T10:46:00-07:00</updated>
    <id>http://rowehl.com/blog/2013/10/28/firefox-os-with-app-manager</id>
    <content type="html"><![CDATA[<p>One of the nice things about
<a href="http://rowehl.com/blog/2013/10/24/firefoxos-1-dot-2-on-zte-open/">getting FFOS 1.2 on my device</a>
is being able to use App Manager instead of the simulator plugin to do
development. Given that
<a href="https://hacks.mozilla.org/2013/10/introducing-the-firefox-os-app-manager/">the App Manager replaces the Simulator Dashboard</a>
in the newest versions of Firefox, it seems like the kind of thing developers
should have access to. So hopefully ZTE figures out a way to get a 1.2+
release on their developer phones.</p>

<p>Note however that the app manager is available in the Firefox 26 series, which
is <a href="http://www.mozilla.org/en-US/firefox/aurora/">current the pre-alpha release</a>.
You can install Aurora side by side with the current stable Firefox release
(that's the default on OS X at least). The app manager is available without
having to install anything, but you'll need to install the ADB helper to
connect to an actual device. Details are in the
<a href="https://developer.mozilla.org/en-US/docs/Mozilla/Firefox_OS/Using_the_App_Manager">using the app manager</a>
document. I've been testing it out primarily with my locally built FFOS 1.2 on
the ZTE Open (inari) device.</p>

<p>Now comes the hard part of trying to figure out what you can put on the
device to make sure everything is working before you dive too far into
hacking around on your own. You'll probably run across things like
<a href="https://github.com/mozilla/firefoxos-quick-start">the Firefox OS Quick Start example</a>
and the <a href="https://github.com/mozilla/mortar">Mozilla templates for Open Web Apps</a>.
None of those seem to be working to generate something you can install on
a device (they work great for the simulator, running on the same machine as
your development tools). Seems like there haven't been a ton of folks working
with physical devices yet.</p>

<p>This
<a href="https://github.com/robnyman/Firefox-OS-Boilerplate-App">Firefox OS boilerplate app</a>
serves as a fantastic starting point however. Just a clone and then
"Add Packaged App" in the app manager and you'll be able to refresh and run
on the device. There's some rough bits, like geolocation isn't working within
the app on my device, and "Take picture" has some issues. However I can
"Pick image" and choose camera as the source and that works okay. And the
rest of the stuff like vibrate, ambient light, device orientation, and check
battery are all working.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[FirefoxOS 1.2 on ZTE Open]]></title>
    <link href="http://rowehl.com/blog/2013/10/24/firefoxos-1-dot-2-on-zte-open/"/>
    <updated>2013-10-24T18:06:00-07:00</updated>
    <id>http://rowehl.com/blog/2013/10/24/firefoxos-1-dot-2-on-zte-open</id>
    <content type="html"><![CDATA[<p>I picked up a <a href="http://www.engadget.com/2013/10/03/zte-open-review/">ZTE Open</a>
Firefox OS device a little while ago. Given that
<a href="https://marketplace.firefox.com/developers/dev_phone">developer hub</a> says
it's a "powerful device aimed at developers and early adopters worldwide" I
figured it would be good for some hackery. I read the specs, so I knew that
"powerful" should be pretty suspect. I was surprised to find out that it's not
really for developers, and increasingly doesn't seem to be all that open.</p>

<p>When I first grabbed it I figured maybe I could use it to just get a feel for
FirefoxOS and the direction the teams were trying to push for. However, the
phone ships with a 1.0.0 version of the operating system and some major basic
features were missing to even use it for a day or two. For instance GMail
contact syncing shows up in FFOS 1.1 (I'm not a Facebook user, so syncing using
the one existing mechanism wasn't an option). Since this was supposed to be
a developer phone for early adopters, I figured that would be easy to remedy.
Not so, there's no official OS updates for the phone planned at all. Weird.</p>

<p>Okay, no problem, I'll use it to just do a little poking around developing
using the Gecko/Gaia stack and getting a feel for it on real hardware. However,
trying to push an app from the simulator it never showed up on the phone.
Rebooted and it popped up. Turns out there's a
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=842725">race condition bug in FFOS 1.0</a>
which really keeps it from being usable as a developer platform.
Of course the pages talking about it say you should "make sure you have the
latest version of Firefox OS on your devices". Which we just established
isn't possible for this developer device, at least not according to ZTE.
Well ain't that just a kick in the crotch?</p>

<p>So of course I ended up doing what I said I wasn't going to do, and dove
straight down the rabbithole of compiling my own recent version of Firefox OS
from source and getting it installed on my ZTE Open device. Turned out to be
way more of an involved process than I expected given that the device is named
the "ZTE Open". I expected that to mean developer friendly. Together with the
Firefox site saying the device was aimed at developers, I didn't see any
reason to second guess that assumption. Here's the process I went through
though, which should get you going from an unboxing to running FFOS 1.2 on
your device. The process isn't too horrible, but making sense of lots of the
existing posts out there and figuring out the right order for a fresh device
took some experimentation.</p>

<p>The first thing to do is apply the
<a href="http://www.ztedevices.com/support/smart_phone/b5a2981a-1714-4ac7-89e1-630e93e220f8.html?type=software">update from ZTE</a>.
This was one of the hardest parts to puzzle out for me. Turns out the firmware
on the model I had was old enough that it was failing to flash the images once
I had them built. There were folks posting that they had gotten certain parts
working, and it was failing for me and others who had recently purchased
devices. Turned out that the original firmware didn't support fastboot, which
is one of the mechanisms for getting the code actually onto the device. That
V1.0.0B02 release from ZTE has instructions for how to load it using the stock
recovery image, and once it's installed you'll be able to use the simple tools
to get your code onto the device. Also nice, with the ZTE provided update.zip
on your SD card you can use recovery mode to get back to a working system if
you end up screwing up the system partition. Which I did dozens of times.</p>

<p>Once you have the ZTE update in make sure you have debugging turned on for
your phone. Go into Settings / Device Information / More Information /
Developer and flip on the Remote Debugging option if it isn't on already.</p>

<p>Next, unfortunately, you'll have to grab a binary image of the
<a href="http://sl.edujose.org/2013/10/adapted-boot-image-for-use-with-b2g.html">boot partition</a>
hacked up and ready to use. This is horrible, and it's the other part that was
really a sticking point trying to figure out. As you'll see later on, for some
reason the boot2gecko build for the inari device (which is the name you use
for building for the ZTE Open) doesn't generate a boot.img. From what I can
tell it doesn't even generate the parts necessary to pull together into a
boot.img. And as I found out through multiple tries, putting the system and
user partitions from a custom build together with the boot from a stock system
you'll generally end up with the OS booting and the UI layers crashing
repeatedly. That's what I got at least.</p>

<p>Once you've got that stuff the build is pretty much as described in the
<a href="https://developer.mozilla.org/en-US/docs/Mozilla/Firefox_OS/Firefox_OS_build_prerequisites">FirefoxOS build docs</a>.
I use an OS X system, but I did my build in a VMWare VM running Ubuntu 13.04.
The tools used to interact with the Firefox OS devices are the same as used
for Android development. And I've done that under a VM tons, so I was pretty
comfortable with that part of the setup. Plus being in a VM meant I could muck
with the stuff in the Linux install as much as I wanted. Below is the actual process I
ran through, getting all the tools in place, configuring, and building. This
assumes you're starting from a completely fresh 13.04 install, you run through
the installer and then let it pull down any updates, then do this:</p>

<script src="https://gist.github.com/mikerowehl/7275342.js"></script>


<p>NOTE: I moved the set of commands to run off to a gist cause Octopress was
prettying up the quotes and making them cut/paste unfriendly.</p>

<p>And then you should have a FFOS 1.2 install runnable on your device. I tested
mine out with my TMobile SIM in the US: phone works, SMS works, data connection
works (though by default it was disabled on mine, just use the notification
pulldown and toggle the cellular data option right next to the wifi toggle).
Hopefully as the device and OS evolve this gets a lot easier and more developer
friendly. Needing to pull a binary boot image from someone else just to get a
fresh build onto a device, that's not good. I was expecting FFOS development
to show up Android development in terms of encouraging developers to work with
the base system. Not the case so far.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[knife-block for Chef Testing]]></title>
    <link href="http://rowehl.com/blog/2013/09/19/knife-block-for-chef-testing/"/>
    <updated>2013-09-19T12:17:00-07:00</updated>
    <id>http://rowehl.com/blog/2013/09/19/knife-block-for-chef-testing</id>
    <content type="html"><![CDATA[<p>A few weeks ago <a href="https://github.com/nathenharvey">Nathen Harvey</a> was kind
enough to stop by and give us a critique of how we do Chef automated testing
and some workflow suggestions. We had been using chef-solo
to do some of the recipe development and automated testing, but all our real
deployments were done using chef-client. And the differences
between solo runs and chef-client runs kept biting us. We had seen the stuff
Lookout Mobile has done to
<a href="http://hackers.lookout.com/2012/04/cookout-at-lookout-with-chef/">run a VM for the chef server</a>
in addition to the node during testing. But that seemed like an awful lot of
overhead. Fortunately Nathen gave us the awesome hack of using different
organizations for the different developers of chef rules, different
organizations for CI, and then the production organization. That gives us
complete isolation of the different working areas, but still keeps setup
relatively simple. w00T!</p>

<p>His suggestion was to use
<a href="https://github.com/greenandsecure/knife-block">the knife-block plugin</a>
to make swapping around between organizations easier. Definitely an awesome
tool, and very useful. But we ran into a few issues because
knife-block uses a different method for finding it's knife.rb file than the
knife command does. So I pushed up a
<a href="https://github.com/mikerowehl/knife-block">fork of the original knife-block code</a>
with a change to how it picks up the configuration location. This version uses
the Chef::Knife config loader to find the actual configuration being used,
and uses that directly. In the original version it borrowed a function from
Chef, but that function tried to find knife config by looking for a .chef
directory somewhere in the parent directories on the filesystem. The real
Chef config loader looking in a bunch of additional places.
So the result was that if you had your
config in ~/.chef and ran your knife block commands from your home dir it worked
fine, but if you cd into /tmp suddenly your knife block commands
would freak out.</p>

<p>Once I dug in and saw what was going on, I figured it would be pretty easy to
fix up. After looking at the Chef code it became obvious why the knife-block
stuff did things the way it did. I hate to have to monkey patch to get things
to work, but the change is actually pretty trivial. I ended up
<a href="https://github.com/mikerowehl/knife-block/blob/494b8c08a45c17c1335a97e4a6a6b08ecdc73c11/lib/chef/knife/block.rb">injecting a get_config_file method</a>
into Chef::Knife so that once I constructed a Knife object I could ask it for
the location of the chef config file. Now if knife itself works, I'm sure
knife-block will end up pulling config from the same location. Useful for when
I need to login to the CI server and poke around to do some debugging
(Bamboo stores the test files outside of the home directory of the bamboo
user in our configuration).</p>

<p>For the testing itself we use some Vagrantfiles with definitions of the
different server types we have. Knife-block provides a nice easy way for me
to test against an mrowehl organization, and then use a devops-test
organization for some automated validation, and finally swap to the prod
organization to push stuff up live. So of course I want to be able to use
the Vagrantfile when I'm testing locally and developing recipes, and use the
same Vagrantfile on the Bamboo server with the devops-test organization to
validate that everything is working. I didn't want to have to go in and edit
the chef-client provisioner config to swap organizations though, and using
something like environment variables to drive it just seemed really ugly.
Fortunately we ran across
<a href="https://coderwall.com/p/dt1idw">this post about pulling vagrant chef-client config from knife.rb</a>
and ended up putting together
<a href="https://gist.github.com/mikerowehl/6631396">our Vagrantfiles so they automatically follow where knife-block is pointed</a>.
Together with the changes in the Vagrant 1.3 series releases to automatically
remove node and client from the server when you do a 'vagrant destroy' it
makes for an awesome testing setup. Just use knife block to swap around to
different organizations and up/destroy your boxes as much as you want,
your wanton path of destruction just gets all swept up automatically behind
you.</p>

<p>With the vagrant config hackery in place it doesn't matter what
organization we want to test against, the text
of the Vagrantfile can stay the same as long as knife is pointed to the right
place. That made it pretty trivial to put together a simple
<a href="https://gist.github.com/mikerowehl/6631010">wrapper Rakefile to clear and populate the organizations</a>.
With those wrappers all our Bamboo server has to do is:</p>

<ul>
<li>grab the latest from our chef-repo with git</li>
<li>'knife block use devops' to swap to our test organization</li>
<li>'rake delete_all' to clean out the test organization</li>
<li>'rake upload_all' to put all the new cookbooks in place</li>
<li>'vagrant up' for the actual test</li>
<li>and then a run always ending task to 'vagrant destroy -f'</li>
</ul>


<p>Fortunately the vagrant up command returns the exit status of the chef-client
run as the status for the command, so picking up failures is pretty trivial.</p>

<p>Of course, this stuff isn't perfect. The tests always run in our 'dev'
environment, which has the cookbook versions unpinned. That's how we can clean
out and reload the organization each time without it causing trouble. Of
course if you had pinned cookbook versions you would have to add in some logic
to make sure you could load the proper version each time you reload. But for
our current level of complexity, just knowing that the latest batch of changes
doesn't completely break is an awesome start.</p>

<p>It's not quite ready for a release yet, but I've also got
<a href="http://www.packer.io/">some Packer templates</a> which converge a node using
chef-client and export the Vagrant friendly box so I can distribute the VM.
Once I have them cleaned up a bit I'll post those too.</p>

<p>Update: The change for knife-block to follow the same knife.rb lookup logic
as Chef has been
<a href="https://github.com/greenandsecure/knife-block/pull/10">merged into the main repo</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scaling Technology]]></title>
    <link href="http://rowehl.com/blog/2013/07/14/scaling-technology/"/>
    <updated>2013-07-14T17:41:00-07:00</updated>
    <id>http://rowehl.com/blog/2013/07/14/scaling-technology</id>
    <content type="html"><![CDATA[<p>A few weeks ago Arte and Mario asked me to swing by to chat with folks participating in
<a href="http://momentum.mobilemonday.us/">the Momentum accelerator</a> to talk about
scaling technology. While we were talking I pointed folks to a few posts and videos of
talks I consider to be some of the root nodes of a lot of other conversations. I'm not
sure I've ever pulled this together before.</p>

<ul>
<li><a href="http://blip.tv/oreilly-velocity-conference/velocity-09-john-allspaw-10-deploys-per-day-dev-and-ops-cooperation-at-flickr-2297883">Allspaw/Hammond - 10+ Deploys Per Day</a></li>
<li><a href="http://www.slideshare.net/deimos/randy-shoup-ebays-architectural-principles">Randy Shoup - Ebay's Architectural Principles</a></li>
<li><a href="http://akfpartners.com/techblog/2008/05/08/splitting-applications-or-services-for-scale/">AKF Partners - Splitting Applications or Services for Scale</a></li>
<li><a href="http://highscalability.com/">High Scalability</a></li>
<li><a href="http://techblog.netflix.com/">Netflix Tech Blog</a></li>
</ul>


<p>That Allspaw/Hammond presentation is the most primary in my opinion. It's the talk
that lots of us consider to be the inflection point of the devops movement, when the
practice started to really gain visibility. What had previously been a random
collection of techniques we didn't have a great way to refer to became "devops".
There's a ton of useful information in that presentation. Not just the overall
concepts of dev and ops working together with a different kind of coupling, but some
specific tools to make that happen like shared metrics, feature flags, and shipping
dark.</p>

<p>The presentation from Randy Shoup has also withstood the test of time fantastically
well. The four architectural principles are great top level items: partition
everything, async everywhere, automate everything, remember everything fails. And the
presentation from AKF Partners dives into a bunch more detail about how to partition
services so that you can just throw hardware at problems. That model also provides a
lot of the basis for most of the conversations I end up having about geographic
distribution of services (which actually sounds exactly like a discussion about how
to design the I/O layer of an operating system, you just swap terminology).</p>

<p>The High Scalability and Netflix blogs provide great concrete examples of what some
of the problems and solutions look like. Principles are great, but like always
there's more than one way to do it. So it's great to have some concrete examples to
poke through. Plus Netflix being one of the pioneers of the static AMI methodology
of infrastructure automation it makes their approaches particularly strongly
opinionated.</p>

<p>The platforms themselves have changed the level of abstraction you need to work at
when putting this stuff into practice. Thanks to MongoDB and Riak we don't have to
wrapper tons of instances of MySQL or Postgres to make a datastore that scales
horizontally. And thanks to services like Elastic Beanstalk, Heroku, and EngineYard
we don't have to pay as much attention to how to distribute load across multiple
application servers. But even though you can count on your platform to remove a
bunch of the details in some cases, it's a good idea to understand the principles.
First of all cause it's possible to misuse the platform and end up not
getting the full advantage you could. But also because platforms can only help out
so far. Eventually you need to crack open the abstractions and either continue
with an application optimized line of evolution, or figure out how to wrapper
additional layers of capability around what the base platform provide. In either
case at least being aware of the principles your underlying platforms are working
on will pay back hugely.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Consistent Test Methodology for Inconsistent Projects]]></title>
    <link href="http://rowehl.com/blog/2013/05/28/consistent-test-methodology-for-inconsistent-projects/"/>
    <updated>2013-05-28T23:43:00-07:00</updated>
    <id>http://rowehl.com/blog/2013/05/28/consistent-test-methodology-for-inconsistent-projects</id>
    <content type="html"><![CDATA[<p>How do you start introducing some testing if you have a huge group of existing
projects, for the most part all implemented using different languages and
technologies? That's the problem I've been poking at recently. The first issue
is that none of the technology choices were made with testability in mind. And
I don't want to have to go through and run a bunch of code refactoring and
reorganization just to start testing. I would much rather start testing, and
then start introducing changes to make things easier to test and to increase
the coverage. The second issue is that we're pretty sure there are some major
architectural changes and redesigns coming in the short term. So to dig in and
harness up the guts of a bunch of systems we know will be changing really
shortly anyway also doesn't seem like a fantastic idea. Plus some of the
changes are more about the operating environment than the code itself, and
a bunch of unit tests won't necessarily help us figure out if the web services
break when we move from MySQL 5.5 to 5.6.</p>

<p>The most obvious and brute-force way would be to recreate the whole end-to-end
environment and create some system tests for it. I think that would be too
brute-force though. I would like our first step to provide some tools that
would be useful to developers and the infrastructure folks. A whole end-to-end
environment might be useful for infrastructure, but would be a burden for
development. Even if this were running up on AWS, imagine having to spin up
a dozen instances and wait for them to initialize just so you could test your
one change. And the system as a whole definitely wasn't built with testability
at the granularity of the entire infrastructure in mind. So good luck being
able to hit even a small set of the conditions the running systems are
subjected to.</p>

<p>No, what we needed to start were a few automated acceptance tests at the
granularity of the individual architecture components. Fortunately, cause much
of the process before was run off manual QA there are collections of test
cases floating around for lots of the components. And there's frequently even
a description on a wiki page of how to configure a QA environment for a given
component (for example how to setup a database, configure Tomcat, and install
and run a web service). So now it's just a matter of being able to script all
that up.</p>

<p>Since I wanted these tests to be useful both for development time checks and
infrastructure validation that meant they needed to run on an environment as
close to production as possible. But setting up a bunch of testing
environments introduces a whole other set of problems potentially as large as
the set we're trying to solve. Spinning up the instances in the cloud might
work, but also introduces a different level of complexity. I wanted
something that a developer could have available right in their project
checkout they could use to validate their work as they go along and ensure
there won't be any surprises when trying to run in production. Fortunately,
that's exactly what <a href="http://www.vagrantup.com/">Vagrant</a> is meant to provide.</p>

<p>With Vagrant and <a href="https://www.virtualbox.org/">VirtualBox</a> on a development
machine it's easy to spawn a VM running the same version of CentOS we're
running in production. The instructions for setting up a QA environment
become
<a href="http://docs.vagrantup.com/v2/provisioning/index.html">provisioning scripts</a>
for the Vagrant config, which automatically get run when the VM launches.
The automation for the test cases themselves or loading data need to be
handled on a case-by-case basis, but with the ability to sync files between
host system and VM and automatically configure port forwarding into the VM
it makes it much simpler to bundle everything into a single command.</p>

<p>Cause we're testing at the same granularity at which these projects are
deployed, we don't have to refactor the projects before we can
start automating some testing. The projects already have well defined input
and output points, which is how they communicate with the rest of the
infrastructure, so we just latch onto those. Now, admittedly, the service
contracts for lots of the projects are fuzzy at best. Cleaning those up is one
of our medium term goals. But at least now we can start with testing in place
and then start changing stuff.</p>

<p>And if the infrastructure folks want to try running on a different distro,
or using a different version of a package, they also now have the tools to
check changes without having to run things through QA.
Make the necessary changes on the VM and then run the script to make sure
nothing has broken.</p>

<p>For this to start looking like a proper continuous delivery test setup we
should be driving the setup of the VM using the same configuration as we use
in production, which is why we're also working on swapping to a more robust
infrastructure automation system than we have currently. For example, Vagrant
allows Chef or Puppet for provisioning instead of using a shell script. And
instead of using the synced filesystem to move data back and forth, the system
under test should be deployed using the same tools and process as the deploy
to production. But at least there's movement in the right direction now.</p>
]]></content>
  </entry>
  
</feed>
