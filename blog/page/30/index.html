
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Miker</title>
  <meta name="author" content="Mike Rowehl">

  
  <meta name="description" content="I was over at CTIA for a while the other day. I already wrote about the BAMF meeting that we had afterward, that kicked ass. But I really should &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://rowehl.com/blog/page/30/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Miker" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-38246826-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Miker</a></h1>
  
    <h2>17th level Hacker</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:rowehl.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2004/10/28/ctia-and-mobility-in-general/">CTIA and Mobility in General</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2004-10-28T11:13:22-07:00" pubdate data-updated="true">Oct 28<span>th</span>, 2004</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I was over at <a href="http://www.ctia.org/conventions_events/index.cfm">CTIA</a> for a while the other day.  I already wrote about the <a href="http://www.mobilityforum.org/2004/10/amazing-turnout.html">BAMF meeting that we had afterward</a>, that kicked ass. But I really should write something of my own about CTIA. I was personally pretty disappointed. I forget who exactly said it, but someone at the BAMF meeting said &#8220;it was all about how to make the carriers even more money.&#8221;  Yea, unfortunately, that is very accurate.  It&#8217;s not that I expect everyone to have the same overall view of mobility as I have.  But I would expect someone to be able to get some representation for the interesting new apps out there.  The closest that I really saw were a couple of booths talking about interesting applications for location based services.  For the most part the location based stuff was all the same normal pitch.  &#8220;We have the largest point of interest database anywhere!&#8221; Yea, sure, but I bet most of the points I&#8217;m most highly interested in still aren&#8217;t in there.</p>

<p>So why do I keep bitching about mobility. Why am I working on getting the BAMF meetings together and trying to hook up people whenever I can?  Cause I really do think that mobility is due for a discontinuous innovation cycle. What&#8217;s that all about? The whole concept of discontinuous innovation I&#8217;ve heard most often associated with Clayton Christenson.  If you&#8217;re interested in hearing a heavily tech industry slanted version of his take, go over to IT Conversations and pick up <a href="http://www.itconversations.com/shows/detail135.html">his speech from the Open Source Business Conference</a>. At a very very high level, the concept is that a new type of technology comes along (or a new type of business model, or a new method of transportation, etc) and eventually completely destroys the old way of doing things.  I think that&#8217;s exactly what we&#8217;re seeing in the mobility industry. There are a lot of really valuable applications that could be out there making peoples lives better. But the deployment of those applications is really held up because the mobile industry is very tied to the old old telecom industry. The telecom industry would really love for mobility to be another one of their cash cows. But the telecom industry wants the mobile industry to fit into the patterns that the telecom industry is already familiar with and is set up to exploit.</p>

<p>So what&#8217;s the big deal you might ask?  If there&#8217;s so much great mobility stuff that could be done, why aren&#8217;t people out there doing it?  Normally that is how it happens.  New companies come up and just wipe out the old companies.  For some information about the concepts behind that look up Schumpeter, and the concepts of <a href="http://en.wikipedia.org/wiki/Creative_destruction">Creative Destruction</a>. The idea there is that markets don&#8217;t allow companies to evolve so much as the market itself evolves through a series of new companies, each set more fit than the last.  So something should come along and replace telecom to form a new version of the mobile market, right?  Well in theory. One of the problems is that there&#8217;s limited spectrum on which wireless can run.  The actual radio signals used to communicate from handsets to the cell towers have to be licensed from the government. Those licenses cost a hell of a lot of money, and there are limited slots available. That means the only people even in the running have to be extremely well funded.  That really rules out just about any form of upstart being able to come in and compete. So the mobile industry is kinds stuck in this world of the old telecom industry, and regulation does it&#8217;s best to make sure that things stay that way.</p>

<p>I personally think that this is one of the reasons that 802.11 and other short range alternatives are positioned as alternatives to cellular.  Technically they should be a completely different category.  Although they do some of the same stuff, I think there&#8217;s more different than there is that&#8217;s the same.  However, 802.11 is unregulated. Anyone can come in and setup a base station and provide service over all small area. 802.11 has grown very rapidly because of that. A somewhat normal user an service their own needs.  Businesses can make inroads to setting up a service network without the crippling charges that they would have to pay for license fees. 802.11 creates a low barrier to entry alternative to cellular, and that encourages experimentation. It invites the startups to play with new ideas, and becomes the defacto platform for the innovative sollutions. In some ways the cellular market is cutting itself off from interesting new applications.</p>

<p>So would I really expect CTIA to pay a lot of attention to the new medium of mobility rather than the existing market of mobility?  No, not really.  But I can still hope sometimes.  At CTIA, the hope was misplaced.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2004/10/22/viewcontroller-separation-in-web-apps/">View/Controller Separation in Web Apps</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2004-10-22T03:34:31-07:00" pubdate data-updated="true">Oct 22<span>nd</span>, 2004</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>A recent article (<a href="http://www.onlamp.com/pub/a/php/2004/10/14/page_controller.html">Migrating to Page Controllers</a>) does an excellent job of combining theory with some concrete examples and immediate benefits. The article provides a simple technique for factoring the controller out of the view processing when writing PHP code. Although not necessary for everything, architecture along this direction can really pay off for web apps. Many of the PHP apps that I&#8217;ve looked at recently have stand alone pages, and that can make them pretty hard to transform. The trend to move all the processing up to the front of the page helps out quite a bit. Programmers now tend to setup their objects and variables all in one block at the top, and then include the display pages with minimal markup to output the dynamic bits. Unfortunately error display still gets stuck into the logic pretty often. It certainly helps out quite a bit to have all the processing done up front, and that&#8217;s half way to the page controller model. The final bit is the refactoring to pull the different views out of the logic and defining a consistent scheme for passing the display info to them. I like the way the description comes off, very practical and tailored towards those who have to refactor their apps to make them look like this.</p>

<p>Check out the earlier article, <a href="http://www.onlamp.com/pub/a/php/2004/07/08/front_controller.html">Building a PHP Front Controller</a>, as well. That gives the same kind of treatment to overall application flow. A minimal set of changes to bring about huge benefits. I&#8217;ve seen a few big products aimed at trying to formalize the separation between overall application flow and page processing, and it can certainly be taken to extremes. When it&#8217;s all said and done, reworking the flow of an application can be complex if you&#8217;re using a flow engine or if you&#8217;re using standalone pages with some application and display objects. I was happy to see that the article included a bit of commentary about when to use a front controller and when it might be unnecessary overhead:</p>

<blockquote><p>Few techniques are suitable for everyone. If your web site updates involve adding new pages in-flight, then the overhead of the map maintenance may work against you. However, if the dynamic nature of your site depends on something outside of the raw pages (such as a database) or if your changes involve carefully-tested migrations, then the Front Controller technique may benefit you long-term.</p></blockquote>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2004/10/21/software-engineering-as-risk-management/">Software Engineering as Risk Management</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2004-10-21T17:11:33-07:00" pubdate data-updated="true">Oct 21<span>st</span>, 2004</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>During the Q&A; at the Niklaus Wirth talk last night someone mentioned formal methods from the <a href="http://en.wikipedia.org/wiki/C._A._R._Hoare">Hoare</a> school of work. Such as <a href="http://en.wikipedia.org/wiki/Hoare_logic">Hoare Logic</a>. In particular they were asking why the work there had fallen out of favor, and wasn&#8217;t used more widely. Which got me thinking about the cost of axiomatic proof of computer systems. Which got me thinking about my background in computer security.</p>

<p>Before I had a job within a large company doing computer security, I used to think that security professionals spent most of their time updating access control lists, looking at packet logs, auditing application code, and doing all sorts of technical stuff. I thought that computer security within organizations was all about keeping people out of your data and off your systems. It&#8217;s not. It&#8217;s about spending as little as possible on issues related to the security of your computers. It&#8217;s not all about keeping people off your systems. It&#8217;s about figuring out how much it costs the company if people do make it onto your systems, and then figuring out how much it keeps to keep those people off your systems, and then picking whichever of those two costs less. Like insurance, it&#8217;s all about risk management.</p>

<p>Of course all kinds of issues get wrapped up in figuring out how much a compromise costs.  If it&#8217;s a public compromise there&#8217;s image damage to take into account, in particular the effect on customer confidence. But at heart it&#8217;s a weighing of the expected losses due to intrustion (chance of occurance times cost per incident) against the cost of prevention. If it costs more to prevent than it does to sweep under the rug, you take the chance with the unprotected system and hope for the best. The security guys make jokes about the only secure computer being one that&#8217;s kept locked in the basement, disconnected from the network, and switched off. That&#8217;s the cost of 100% security, 0 productivity. That&#8217;s one of the nasty points of security, it is impossible to reduce the exposure risk to 0% and still get work done with the system. No matter how much money you put in, there&#8217;s always a chance of compromise. And the cost grows exponentially as you get closer to the low end of the risk scale. More and more money buys you less and less relative change in security.</p>

<p>Given this environment any business doing work on the Internet would be crippled with security costs if they were trying for absolute security. Nothing would ever get done. Ever. So the solution to costs spiralling out of control is the risk management approach. An implementation plan is based not on doing things absolutely correctly, but based on what can be done that will cost less than the perceived cost of doing nothing at all. I see a direct correlation here with software engineering. The question is not how to build a system which is 100% correct, but how to build a system that delivers more value than it costs to develop. In my mind that&#8217;s why the ideas from the formal verification end of computer science aren&#8217;t in more general use. The cost of training people with these tools, and then using them in building systems, raises the cost of systems beyond the cost of just not writing them at all.</p>

<p>Most business people understand the concept, but I think it&#8217;s probably so ingrained that it rarely get articulated explicitly. And this is probably partially responsible for the tension between business and technical concerns in most projects. It doesn&#8217;t help that most software engineering practices don&#8217;t acknowlege this end of the engineering tradeoff at all (with the very notable exception of agile practices, something that I&#8217;m just realizing as I&#8217;m writing this). It&#8217;s hard to come up with numbers attached to the exposure risk in security, and that analysis is normally done at a stage when the issue is much better understood than it is during the development stage. In the absence of those numbers, it seems as if there are very few instances where system development rigor makes it all the way out to formal verification and still stays below the cost of dealing with errors. Given the huge cost associated with changing development practices, a very strong case would have to be made before the attempt could be considered.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2004/10/20/niklaus-wirth-2/">Niklaus Wirth 2</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2004-10-20T13:18:29-07:00" pubdate data-updated="true">Oct 20<span>th</span>, 2004</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>The success of Pascal came many years after it was done, due to the availability of microcomputers. Now there were lots of people available to program who didn&#8217;t have to unlearn Fortran. It was driven forward by Borland making the compiler available for only 50 dollars, when other compilers cost thousands. This made a mass market for Pascal.</p>

<p>Many systems at this point could only be built by teams. A way to partition systems was necessary, and led to the the concept of modules, and the development of Modula. Most people still stck with Pascal. Wirth expected everyone in their right mind to switch from Pascal to Modula, but they didn&#8217;t.</p>

<p>Started working on Oberon, which was implemented based on object oriented techniques. But it was never recognized as an object oriented language. It didn&#8217;t cleave to the trends at the time, so it was excluded.</p>

<p>So&#8230; This is supposed to be about how he got interested in languages. Does he consider a career spent on programming languages well spent? He has always considered himself a teacher, but he knows he can&#8217;t teach good design. That takes examples, and is supported by a good language. A complicated syntax and voluminous description is a sign of a poor language. Rules governing the language must be determined apart from the implementation.</p>

<p>Measured on this scale, progress has been made. It was worth the time. Most important now is educating programmers on how to use those tools as best as they can. There is a lot more to do.</p>

<p>The essence of programming languages:</p>

<p>To provide a level of abstraction from details of computers.</p>

<p>To provide a suitable model of computation</p>

<p>To allow mathematical reasoning without recourse to knowledge about the underlying mechanisms</p>

<p>For this we require a concise and precise definition.  Fat manuals are a reliable symptom of failure</p>

<p>Then comes Q and A.</p>

<p>The story of Wirth building a helecopter control system. The trick was to make it disappear. It turned into a cyclic turning process. Taking values from sensors and moving actuators. The whole system is Oberon, only one page of code.</p>

<p>Overloading and templates: Wirth says overloading makes sense and belongs in the basic object oriented toolbox. However he says he has some reservations about the way that most systems implement it, Oberon did it very elegently. Never was able to make good use of templates, but some people might.</p>

<p>Knuth stood up and asked about recursion being missing from the original Pascal spec.  It was true, but it was there by the first implementation.</p>

<p>Question about what languages will people be using in thirty years. Wirth says that most people don&#8217;t program the way that he used to. Now they pick up bits of code from other places. This leads to bloat. In thirty years there will just be more bloat.</p>

<p>Question about functional programming. He says they are interesting, but not really very useful. All so called functional languages have an assignment hidden somewhere. He thinks that people who are fans of functional languages are actually fans of programming without non-local variables.  The fans say thats really very close to the truth.  And Wirth says that he programs like that himself.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2004/10/20/niklaus-wirth/">Niklaus Wirth</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2004-10-20T12:38:08-07:00" pubdate data-updated="true">Oct 20<span>th</span>, 2004</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Here&#8217;s some quick notes from the talk that Niklaus Wirth gave at the Computer History Museum on Oct 20th. The topic was &#8220;How I Became Interested In Computer Languages&#8221;.</p>

<p>Professsional career really started in Berkley. Thats when his real experience with computers started. Was always into modeling, and a lot of qualites cary over. Using tools, experimenting, persevering in spite of crashes. Liked physics and chemistry, and didn&#8217;t really pay attention to languages.</p>

<p>When model airplane parts became available, he was forced to study electronics in order to use them. Got theory at University and practice at home. Eary playing with computers took a long time, and ran into people who were working on a translator for computer languages, called a &#8220;compiler&#8221;. Only one person really understood the program, and it was messy, so he decided that the practice of building compilers need structure.</p>

<p>The early version lacked abstraction, it did not abstract away details of the computer hardware. Still it was easier than previous methods.</p>

<p>At the time thing were beautiful in Berkley, golden years. Before Flower Power. He joined in a seminar about Algol. Based on mathematical rigor. There was a clear way to figure out if a text was a valid program. Decided to write a compiler for it. The compiler was short and very simple. Met a witty and engaging person who tossed about some interesting ideas. Made Wirth think about a reduced Algol that had the same expressive power as the original. Wijngaarden.</p>

<p>Became a professor, and people were still trying to figure out what to teach about computers besides languages.  IE. Data structures. The challenge was to introduce rigor into semantics as well as syntax. Although Algol was interesting it didn&#8217;t suit practice very well.</p>

<p>Implemented Algol-W at SLAC. That was a stepping stone to his professional career. He made frequent trips, even overseas, which was not common at the time. There were heated discussions all over about the future of Algol. Algol always remained an academic exercise, never accepted into industry.</p>

<p>Programming became more and more complex, projects became very large, and even large companies drifted dangerously close to collapse. They were not able to deliver on their promises. This is what led to structured programming. Now one person didn&#8217;t have to understand the whole system. This was very far ahead of its time (and maybe still is).</p>

<p>Thing were getting bad with the Vietnam war, and he was offered a job in Zurich to continue work on Algol. He took it. Without having to work with comittee, he was able to work towards what he wanteed. The stuff he wanted stemed from having to teach languages and keeping the compiler clean. The idea was to write the compiler quick in Fortran, and implement the new lanuage, Pascal. Eventually, they had to scrap it. The decision was made to write Pascal in Pascal. The Pascal compiler was translated into another language for which there was a compiler to bootstrap.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2004/10/16/notes-from-new-geography/">Notes From New Geography</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2004-10-16T11:31:17-07:00" pubdate data-updated="true">Oct 16<span>th</span>, 2004</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Two sets of notes from the New Geography workshop put on by the <a href="http://www.iftf.org">Institute For The Future</a></p>

<ul>
<li><p>Freds House covers <a href="http://www.fredshouse.net/archive/000262.html">the first day</a></p></li>
<li><p>Future Now covers <a href="http://blogger.iftf.org/Future/000578.html">the second day</a></p></li>
</ul>


<p>I wasn&#8217;t able to make it unfortunately. From the sounds of it some really interesting topics were discussed. The transformative power of having information available either directly as or tied to maps and geographic location is something I think we&#8217;ve just started to realize. Projects like <a href="http://yellowarrow.org">YellowArrow</a> are a great way to raise the visability, but like many technologies this is one that really requires network effects to get going. Most geographic applications aren&#8217;t all that interesting unless there&#8217;s geographically marked up data to look at. Some commercial sources will output data like that, but of course that&#8217;s because they want to make a dime off the customers. Those could be interesting application, but aren&#8217;t where I expect the main push to be. I think the location based services really take off when you start connecting person to person. Location based services I think will take a bottom up form, much like SMS itself. Most users of SMS aren&#8217;t interested in getting just fresh news or stock quotes delivered to their handsets. Although those are valid applications, the main use for SMS is communicating with friends and colleagues. I think the tipping point for location based services will come when they can fufull the same kind of role. Connecting people to their friends and colleagues. Not to the nearest Pizza Hut.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2004/10/12/niklaus-wirth-speaking/">Niklaus Wirth Speaking</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2004-10-12T16:42:18-07:00" pubdate data-updated="true">Oct 12<span>th</span>, 2004</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Niklaus Wirth is <a href="http://www.computerhistory.org/events/index.php?id=1097188078">speaking at the Computer History Museum</a> in Mountain View on the topic &#8220;How I Became Interested in Programming Languages&#8221;. Wirth is one of those names that pops up over and over again in computer science, like Knuth. I&#8217;ve never heard him speak before, and I&#8217;m certainly not going to pass up the opportunity to. An RSVP is required, so visit that link and fill out the registration info if you&#8217;re planning to go.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2004/10/11/music-and-metadata-panel-in-palo-alto/">Music and Metadata Panel in Palo Alto</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2004-10-11T03:34:20-07:00" pubdate data-updated="true">Oct 11<span>th</span>, 2004</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>There&#8217;s an <a href="http://www.sdforum.org/SDForum/Templates/CalendarEvent.aspx?CID=1461&amp;mo=10&amp;yr=2004">SDForum panel presentation</a> tomorrow about Music and Metadata:</p>

<blockquote><p>Over the past 13 years, the web has grown from a simple content distribution mechanism into a vast repository of information and on-line data. As the amount of information available has exploded, and as the number of people using the internet as a source of both information and a way to purchase goods and services has increased exponentially, the use of metadata (or data about the data) has become more important.</p></blockquote>

<p>Early experiments included Epinion&#8217;s reviews and Amazon&#8217;s collaborative filtering. Current experiments include RSS (metadata about which information is new), FOAF (metadata about social relationships), and the semantic web (expressive ways to encode metadata).</p>

<p>In this panel discussion, participants from the bleeding edge of musical metadata will talk about their vision for the future of music, and how metadata will help make that happen.</p>

<p>Fits in with a bunch of stuff I&#8217;m interested in. Why is stuff like this important? Because if we want to transform content from the top-down push that is today into a bottom-up form that looks more like peer-to-peer sharing than corporate content distribution, making systems that allow people to easily find what they&#8217;re looking for are much more important. The current model is that you flip on the radio or walk into a music store to find what you want. The content is pumped out over a number of channels, which exist pretty much just to give you a place to find music when you&#8217;re looking for music. But if the music exists &#8220;somewhere out there&#8221; on the Internet, how can one find what they&#8217;re looking for without reintroducing the controlling distribution channel. In some ways this is an analog of what has been happening with blogging replacing some forms of traditional media. For an example of some of the work going on in the area visit <a href="http://playlist.musicbrainz.org/playlist/moin.cgi/">the XSPF wiki</a>.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2004/10/08/semantic-xhtml/">Semantic XHTML</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2004-10-08T16:52:06-07:00" pubdate data-updated="true">Oct 8<span>th</span>, 2004</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Brian Cantoni has <a href="http://www.cantoni.org/2004/09/28/sdforum_technorati_talk">a good writeup of a talk about Semantic XHTML</a> given by Kevin Marks and Tantek Celik.  The slides are <a href="http://tantek.com/presentations/20040928sdforumws/semantic-xhtml.html">available online</a> as well. There&#8217;s some good stuff in there. Lately I&#8217;ve been working a bunch with the idea of mixing in additional information with web content. The ideas become much more interesting with <a href="http://davenet.scripting.com/2003/01/06/firstEssayOfTheYear">the read-write-web</a> in my opinion. There&#8217;s an elegant layered model for moving user content around evolving. The APIs that started out with blogging, like MetaWeblog and Atom, provide a transport mechanism. Semantic XHTML can provide the structure for those posts to turn a blog post into something more, like an address book update or a calendar event. And those two realms can remain distinct. A standard blog post without semantic information remains a valid post, using Semantic XHTML in some cases doesn&#8217;t preclude using standard HTML in others. For instance the metadata for a <a href="http://joi.ito.com/joiwiki/MicroContentBlurb">micro-content</a> system could be passed as semantic XHTML in a blog post. Systems used to tend to either require metadata or not allow it at all. New systems, like <a href="http://del.icio.us">the del.icio.us bookmarking system</a>, allow for optional metadata and don&#8217;t enforce any restrictions on how the info is used.</p>

<p>The term for this free-for-all kind of metadata is currently <a href="http://www.corante.com/many/archives/2004/08/25/folksonomy.php">folksonomy</a>. And like many of the points of interest within the area called social software, it&#8217;s simply a reversal of what &#8220;common knowledge&#8221; computer information management says is an unworkable system. Traditional knowledge said that unstructured metadata for categorization would lead to chaos, you need a strict taxonomy. Del.icio.us has proven that chaos does indeed have it&#8217;s uses, even without a taxonomy the system is still very useful. Traditional knowledge says that any public internet resource needs access control and authentication. Wikis (and the <a href="http://www.wikipedia.com">Wikipedia</a> in particular) have proven that there are cases where a free-for-all actually increases the rate of production. Even after you factor in time to reverse graffiti and malicious updates. So what are some of the other assumptions that we can attempt to reverse in looking for areas where common knowledge tells us some system is &#8220;unworkable&#8221;?</p>

<p>Well, how about the application interfaces themselves? Traditional system architecture says that in order to build an application you need a set of cooperating APIs, and that accessing remote resources requires something like SOAP/WSDL or CORBA in order to provide a description of the interface and introspection and versioning. But there&#8217;s been a lot of resistence to this view of the network, such as the RESTian response to web services. Most recently the <a href="http://www.jot.com/">JotSpot</a> tool seems to have embraced the idea also. Applications aren&#8217;t bits of binary code linking together local libraries into a strict framework of classes and objects, they&#8217;re transformations and pointers linking togther and unifiying resources out on the web. It&#8217;s a completely different take on the control vs. flexibility tradeoff than is normally taken. Don&#8217;t errect a strict barrier arround your application to isolate it from the world. Provide every affordance and convenience to allow data in any form to contribute. I personally expect a lot more work in this direction over the next couple of months. It just logically lays in line with a series of movements that have been taking shape and gaining momentum for at least a year.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2004/10/05/bunch-of-gnomedex-links/">Bunch of Gnomedex Links</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2004-10-05T00:54:08-07:00" pubdate data-updated="true">Oct 5<span>th</span>, 2004</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://www.gnomedex.com">Gnomedex</a> was fantastic. Lots of people to talk to, and I thought the panel discussions were interesting even if others found some fault with them. Being at the conf you hear about a bunch of stuff that it&#8217;s hard to find your way to if you weren&#8217;t there to hear the off the cuff comments or pick up the links from IRC (I really should have logged the channel&#8230; oops). So here&#8217;s a bunch of stuff, some from the <a href="http://www.bitsplitter.net/blog/index.php?p=338">previous page I had</a> and some new stuff:</p>

<ul>
<li><p>Eric Rice did <a href="http://eric.blognews.com/blog/_archives/2004/10/2/153034.html">a podcast</a> from the conf. He&#8217;s really into the podcast idea. Seems to fit in as a logical extension of the <a href="http://www.audioblog.com/">Audioblog</a> stuff he&#8217;s doing already. He says a regular show is probably in the works, so keep an eye out for that.</p></li>
<li><p>Dave Taylor has <a href="http://www.free-web-money.com/cat_pay_per_click_ppc_advertising.html">a page to go along with The Future of Online Advertising panel</a>. It&#8217;s not an exhaustive list, but enough to get your fingers into the concepts. Great resource.</p></li>
<li><p>There were a whole bunch of people taking pictures:</p>

<ul>
<li><p><a href="http://www.flickr.com/photos/peterkaminski/sets/16646/">Peter Kaminski</a> - who was also very cool, I got to speak to Peter for a while.  He works for SocialText and I have a lot of interest in the collaborative application space.</p></li>
<li><p><a href="http://ponzarelli.com/blog/Photos">Ponzi</a> - I didn&#8217;t get to speak to her, but have second hand information from <a href="http://kalsey.com/">Adam</a> that both her and Chris really went out of their way to help him when he wasn&#8217;t feeling well. Now that just kicks ass.</p></li>
<li><p><a href="http://kenlayne.com/2004/10/foto-fun.html">Ken Layne</a> - provides some commentary on photos that were actually taken by <a href="http://marc.buzznet.com/user/">Marc Brown</a>. I didn&#8217;t talk to Ken, but did get to speak to Marc. Marc is going to be in San Francisco for <a href="http://www.ctia.org/">CTIA</a>, so we&#8217;re probably going to get together for a Bird of a Feather meeting. Check out <a href="http://www.mobilityforum.org">Bay Area Mobility Forum</a> for more info about that.</p></li>
<li><p><a href="http://www.flickr.com/photos/pjmorr">Phil Morrison</a> - has some great pics up now. We spoke in the IRC channel, but never synced up in the real world. Yet still I feel like we met&#8230; There&#8217;s probably a lesson in there somewhere.</p></li>
<li><p><a href="http://www.noded.com/noded/">JR Noded</a> - has a few higher quality pictures up. He was sitting at our table for a bit, very nice guy</p></li>
</ul>
</li>
<li><p>There were a bunch of people who were raving about <a href="http://blog.blogware.com/blog">Blogware</a>, Eric Rice in particular. I got a chance to speak to Ross Rader about it as well, he provided a nice high level overview. The summary that I pulled out of the discussion is that it&#8217;s a tool based more on sharing than on publishing. If that&#8217;s correct, I think it should be very interesting.</p></li>
<li><p>Some of the attendees set up <a href="http://www.arete.cc/godmug/">a Mac Users Group</a> for the conf. There were a hell of a lot of glowing Apple logos all over the place. Personally, I&#8217;m really jealous of the battery life the things get. I&#8217;ve got my eye turned that way when it&#8217;s time for the next system.</p></li>
</ul>

</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/31/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/29/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>About Me</h1>
  <p>
    I&#8217;m Mike Rowehl, a programmer and entrepreneur living in the San Francisco bay area.
    I&#8217;ve been working in the mobile industry for a long time, and have been involved in launching a bunch of startups in the space.
    I&#8217;ve been programming and working with open source projects for even longer.
    I&#8217;m a fan of high tech, and high tech startups in particular.
  </p>
</section>
<section>
  <h1>Other Info</h1>
  <ul>
      <li><a href="http://twitter.com/miker">Twitter</a></li>
      <li><a href="https://www.linkedin.com/in/miker">LinkedIn</a></li>
      <li><a href="http://stackoverflow.com/users/506507/mikerowehl">Stackoverflow</a></li>
      <li><a href="http://github.com/mikerowehl">Github</a></li>
      <li><a href="http://angel.co/mike-rowehl">AngelList</a></li>
      <li><a href="http://thisismobility.com/blog/">This is Mobility</a></li>
      <li><a href="http://delicious.com/miker">Delicious</a></li>
      <li><a href="http://www.crunchbase.com/person/mike-rowehl">Crunchbase</a></li>
      <li><a href="/resume.html">My Resume</a></li>
  </ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/05/28/consistent-test-methodology-for-inconsistent-projects/">Consistent Test Methodology for Inconsistent Projects</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/05/25/rebooting-an-engineering-organization/">Rebooting an Engineering Organization</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/03/09/why-i-suck-at-angel-investing/">Why I Suck at Angel Investing, and My Plan</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/02/06/use-of-time/">Use of Time</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/02/04/resurrection/">Resurrection</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("miker", 10, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/miker" class="twitter-follow-button" data-show-count="false">Follow @miker</a>
  
</section>


<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/mikerowehl">@mikerowehl</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'mikerowehl',
            count: 5,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


<section>
  <h1>On Delicious</h1>
  <div id="delicious"></div>
  <script type="text/javascript" src="http://feeds.delicious.com/v2/json/miker?count=3&amp;sort=date&amp;callback=renderDeliciousLinks"></script>
  <p><a href="http://delicious.com/miker">My Delicious Bookmarks &raquo;</a></p>
</section>




  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Mike Rowehl -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  





  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
