---
date: 2005-04-04 19:00:05
layout: post
title: MoMo April Igor Jablokov
---

Igor Jablokov presenting at [Mobile Monday](http://www.mobilemonday.com/2005/04/april-mobile-monday-tonight.html) -

He was talking about a mixed voice and text interface, allowing users to speak at applications and application to speak back.  It has a markup that hooks into an existing application.  An example was given of voice enabling something like Friendster. I assume this is something like VoiceXML, which gave keywords and mappings to screen translations (state transitions).  There's a W3C working group, and they've used existing W3C standards to build the markup they use. I think [this is the right starting point](http://www-306.ibm.com/software/pervasive/multimodal/) for more information about what he was talking about.

What's the problem with the mobile web? cumbersome and frusterating, lots of screens, keypads and screens are too small, UI for every mobile is different.

Providers - Want distance between licensed content and end users decreased.

14.8% of phone ownders use data services (that's probably pretty optimistic) Cellular operaters want more users to use data services but adoption has been slow.

Eventually all the providers will be providing the same good enough service,  the differentiating feature will be the applications available.

Multimodal refers mixed voice and text interface. Both for the user input and for the output.

"You don't need a PHd in CS any more to develop a voice application.

They provide a markup that allows for voice interaction.

Opera will release a browser with voice capability, version 8 in about a month or so.

Extreme blue, an application they have. A multimodal social mobile service.

Lots of the capabilities are on the device currently (voice generation, voice browser), eventually that might go up to the server.  You can get the components necessary and run them with a relatively generic server architecture.Looks to be application server based (WebSphere, JBoss).  Too bad.

IBM leadership in speech.  More than 30 years. 250 speech patents. 100 researchers in 15 languages.

Speech interface is natural for a phone, people already talk into a phone. They don't talk into a computer.

Some comparison with the SALT version from Microsoft, which apparently isn't open standards based.

Single word can take you to the point you want. You should be able to just say "Help" or "Customer service" and get to the point you want.

Eclipse interface, drag and drop, but you can use any text editor to create it.
